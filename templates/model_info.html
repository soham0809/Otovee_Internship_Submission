<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>PCOS Model Performance</title>
    <style>
      body {
        font-family: "Segoe UI", Tahoma, Geneva, Verdana, sans-serif;
        background: linear-gradient(135deg, #c9d6ff, #e2e2e2);
        margin: 0;
        padding: 20px;
        min-height: 100vh;
      }

      .container {
        max-width: 1200px;
        margin: 0 auto;
        padding: 20px;
      }

      .header {
        text-align: center;
        margin-bottom: 30px;
      }

      .header h1 {
        color: #333;
        margin-bottom: 10px;
        text-shadow: 1px 1px 3px rgba(0, 0, 0, 0.2);
      }

      .header p {
        color: #666;
        max-width: 800px;
        margin: 0 auto;
      }

      .card {
        background: #ffffff;
        padding: 30px;
        border-radius: 20px;
        box-shadow: 10px 10px 20px rgba(0, 0, 0, 0.15),
          -10px -10px 20px rgba(255, 255, 255, 0.8);
        margin-bottom: 30px;
      }

      h2 {
        color: #333;
        border-bottom: 2px solid #f0f0f0;
        padding-bottom: 10px;
        margin-top: 0;
      }

      .metrics-grid {
        display: grid;
        grid-template-columns: repeat(auto-fill, minmax(200px, 1fr));
        gap: 20px;
        margin-bottom: 30px;
      }

      .metric-card {
        background: #f9f9f9;
        padding: 20px;
        border-radius: 15px;
        text-align: center;
        box-shadow: 5px 5px 10px rgba(0, 0, 0, 0.05);
        transition: transform 0.3s ease;
      }

      .metric-card:hover {
        transform: translateY(-5px);
      }

      .metric-name {
        font-weight: bold;
        color: #555;
        margin-bottom: 10px;
      }

      .metric-value {
        font-size: 1.8em;
        font-weight: bold;
        color: #6a11cb;
      }

      .models-comparison {
        overflow-x: auto;
      }

      table {
        width: 100%;
        border-collapse: collapse;
        margin: 20px 0;
      }

      th, td {
        padding: 12px 15px;
        text-align: left;
        border-bottom: 1px solid #ddd;
      }

      th {
        background-color: #f5f5f5;
        font-weight: bold;
        color: #333;
      }

      tr:hover {
        background-color: #f9f9f9;
      }

      .best-model {
        background-color: #e8f5e9;
      }

      .error {
        background-color: #ffebee;
        color: #c62828;
        padding: 15px;
        border-radius: 10px;
        text-align: center;
      }

      .back-link {
        display: inline-block;
        margin-top: 20px;
        color: #6a11cb;
        text-decoration: none;
        font-weight: 500;
        transition: 0.3s;
      }

      .back-link:hover {
        color: #2575fc;
        text-decoration: underline;
      }

      @media (max-width: 768px) {
        .metrics-grid {
          grid-template-columns: repeat(2, 1fr);
        }
      }

      @media (max-width: 480px) {
        .metrics-grid {
          grid-template-columns: 1fr;
        }
      }
    </style>
  </head>
  <body>
    <div class="container">
      <div class="header">
        <h1>PCOS Prediction Model Performance</h1>
        <p>Detailed evaluation metrics and model comparison for the PCOS prediction system</p>
      </div>

      {% if error %}
      <div class="card">
        <div class="error">
          {{ error }}
        </div>
        <a href="/" class="back-link">← Back to Prediction</a>
      </div>
      {% else %}
      <div class="card">
        <h2>Best Model: {{ model_data.best_model }}</h2>
        <p>The following metrics represent the performance of our best model on the test dataset:</p>
        
        <div class="metrics-grid">
          <div class="metric-card">
            <div class="metric-name">Accuracy</div>
            <div class="metric-value">{{ "%.2f"|format(model_data.accuracy * 100) }}%</div>
          </div>
          <div class="metric-card">
            <div class="metric-name">F1 Score</div>
            <div class="metric-value">{{ "%.2f"|format(model_data.f1_score * 100) }}%</div>
          </div>
          <div class="metric-card">
            <div class="metric-name">Precision</div>
            <div class="metric-value">{{ "%.2f"|format(model_data.precision * 100) }}%</div>
          </div>
          <div class="metric-card">
            <div class="metric-name">Recall</div>
            <div class="metric-value">{{ "%.2f"|format(model_data.recall * 100) }}%</div>
          </div>
          {% if model_data.roc_auc %}
          <div class="metric-card">
            <div class="metric-name">ROC AUC</div>
            <div class="metric-value">{{ "%.2f"|format(model_data.roc_auc * 100) }}%</div>
          </div>
          {% endif %}
          <div class="metric-card">
            <div class="metric-name">MCC</div>
            <div class="metric-value">{{ "%.2f"|format(model_data.mcc * 100) }}%</div>
          </div>
        </div>
      </div>

      <div class="card">
        <h2>Model Comparison</h2>
        <p>Cross-validation results for all models evaluated during training:</p>
        
        <div class="models-comparison">
          <table>
            <thead>
              <tr>
                <th>Model</th>
                <th>Accuracy</th>
                <th>F1 Score</th>
                <th>ROC AUC</th>
              </tr>
            </thead>
            <tbody>
              {% for model_name, metrics in model_data.cv_results.items() %}
              <tr {% if model_name == model_data.best_model %}class="best-model"{% endif %}>
                <td>{{ model_name }}</td>
                <td>{{ "%.2f"|format(metrics.accuracy * 100) }}%</td>
                <td>{{ "%.2f"|format(metrics.f1 * 100) }}%</td>
                <td>{{ "%.2f"|format(metrics.roc_auc * 100) }}%</td>
              </tr>
              {% endfor %}
            </tbody>
          </table>
        </div>
      </div>

      <div class="card">
        <h2>Model Interpretation</h2>
        <p>Understanding the model's performance:</p>
        
        <h3>What these metrics mean:</h3>
        <ul>
          <li><strong>Accuracy:</strong> The proportion of correct predictions (both true positives and true negatives) among the total number of cases examined.</li>
          <li><strong>F1 Score:</strong> The harmonic mean of precision and recall, providing a balance between the two.</li>
          <li><strong>Precision:</strong> The proportion of positive identifications that were actually correct.</li>
          <li><strong>Recall:</strong> The proportion of actual positives that were identified correctly.</li>
          <li><strong>ROC AUC:</strong> Area Under the Receiver Operating Characteristic curve, measuring the model's ability to distinguish between classes.</li>
          <li><strong>MCC:</strong> Matthews Correlation Coefficient, a balanced measure even with class imbalance.</li>
        </ul>
        
        <h3>Model Improvements:</h3>
        <p>Our enhanced model includes:</p>
        <ul>
          <li>Advanced feature engineering with hormone ratios and transformations</li>
          <li>Robust handling of outliers and missing values</li>
          <li>Class imbalance correction using SMOTE-Tomek</li>
          <li>Ensemble methods to combine multiple model predictions</li>
          <li>Cross-validation to ensure reliable performance estimates</li>
        </ul>
      </div>

      <a href="/" class="back-link">← Back to Prediction</a>
      {% endif %}
    </div>
  </body>
</html>
